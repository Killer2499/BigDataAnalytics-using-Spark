{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/root/Desktop/spark-2.4.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('worldcup.csv').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----+------+----+------+--------------+---------+-----------+----------+-----------+----------+\n",
      "| _c0|  _c1|  _c2| _c3|   _c4| _c5|   _c6|           _c7|      _c8|        _c9|      _c10|       _c11|      _c12|\n",
      "+----+-----+-----+----+------+----+------+--------------+---------+-----------+----------+-----------+----------+\n",
      "|null|Score|Overs| RPO|Target|Inns|Result|    Opposition|   Ground| Start Date|  Match_ID|    Country|Country_ID|\n",
      "| 412|  250| 48.3|5.15|  null|   1|   won|       v India|  Kolkata| 3 Jan 2013|ODI # 3315|   Pakistan|         7|\n",
      "| 680|  165| 48.0|3.43|   251|   2|  lost|    v Pakistan|  Kolkata| 3 Jan 2013|ODI # 3315|      India|         6|\n",
      "| 413|  157| 48.5|3.21|   168|   2|  lost|       v India|    Delhi| 6 Jan 2013|ODI # 3316|   Pakistan|         7|\n",
      "| 681|  167| 43.4|3.82|  null|   1|   won|    v Pakistan|    Delhi| 6 Jan 2013|ODI # 3316|      India|         6|\n",
      "| 117|  198| 40.0|4.95|   306|   2|  lost|   v Australia|Melbourne|11 Jan 2013|ODI # 3317|   SriLanka|         8|\n",
      "|1076|305/5| 50.0|6.10|  null|   1|   won|   v Sri Lanka|Melbourne|11 Jan 2013|ODI # 3317|  Australia|         2|\n",
      "| 682|316/9| 50.0|6.32|   326|   2|  lost|     v England|   Rajkot|11 Jan 2013|ODI # 3318|      India|         6|\n",
      "| 836|325/4| 50.0|6.50|  null|   1|   won|       v India|   Rajkot|11 Jan 2013|ODI # 3318|    England|         1|\n",
      "| 118|172/2| 40.1|4.28|   171|   2|   won|   v Australia| Adelaide|13 Jan 2013|ODI # 3319|   SriLanka|         8|\n",
      "|1077|  170| 46.5|3.62|  null|   1|  lost|   v Sri Lanka| Adelaide|13 Jan 2013|ODI # 3319|  Australia|         2|\n",
      "| 683|285/6| 50.0|5.70|  null|   1|   won|     v England|    Kochi|15 Jan 2013|ODI # 3320|      India|         6|\n",
      "| 837|  158| 36.0|4.38|   286|   2|  lost|       v India|    Kochi|15 Jan 2013|ODI # 3320|    England|         1|\n",
      "| 119| 75/6| 20.0|3.75|    75|   2|   won|   v Australia| Brisbane|18 Jan 2013|ODI # 3321|   SriLanka|         8|\n",
      "|1078|   74| 26.4|2.77|  null|   1|  lost|   v Sri Lanka| Brisbane|18 Jan 2013|ODI # 3321|  Australia|         2|\n",
      "| 684|157/3| 28.1|5.57|   156|   2|   won|     v England|   Ranchi|19 Jan 2013|ODI # 3322|      India|         6|\n",
      "| 838|  155| 42.2|3.66|  null|   1|  lost|       v India|   Ranchi|19 Jan 2013|ODI # 3322|    England|         1|\n",
      "| 277|  208| 46.2|4.48|  null|   1|  lost| v New Zealand|    Paarl|19 Jan 2013|ODI # 3323|SouthAfrica|         3|\n",
      "| 551|209/9| 45.4|4.57|   209|   2|   won|v South Africa|    Paarl|19 Jan 2013|ODI # 3323|  Newzealad|         5|\n",
      "| 120| 14/0|  3.2|4.20|   223|   2|   n/r|   v Australia|   Sydney|20 Jan 2013|ODI # 3324|   SriLanka|         8|\n",
      "+----+-----+-----+----+------+----+------+--------------+---------+-----------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() #printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " '_c1',\n",
       " '_c2',\n",
       " '_c3',\n",
       " '_c4',\n",
       " '_c5',\n",
       " '_c6',\n",
       " '_c7',\n",
       " '_c8',\n",
       " '_c9',\n",
       " '_c10',\n",
       " '_c11',\n",
       " '_c12']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #prints columns of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructField,StringType,\n",
    "                               IntegerType,StructType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('_c0',IntegerType(),True),\n",
    "               StructField('_c1',StringType(),True)]#3rd field to be null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc =StructType(fields=data_schema)#Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('worldcup.csv',schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['_c0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| _c0|\n",
      "+----+\n",
      "|null|\n",
      "| 412|\n",
      "| 680|\n",
      "| 413|\n",
      "| 681|\n",
      "| 117|\n",
      "|1076|\n",
      "| 682|\n",
      "| 836|\n",
      "| 118|\n",
      "|1077|\n",
      "| 683|\n",
      "| 837|\n",
      "| 119|\n",
      "|1078|\n",
      "| 684|\n",
      "| 838|\n",
      "| 277|\n",
      "| 551|\n",
      "| 120|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('_c0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('_c0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| _c0|  _c1|\n",
      "+----+-----+\n",
      "|null|Score|\n",
      "| 412|  250|\n",
      "| 680|  165|\n",
      "| 413|  157|\n",
      "| 681|  167|\n",
      "| 117|  198|\n",
      "|1076|305/5|\n",
      "| 682|316/9|\n",
      "| 836|325/4|\n",
      "| 118|172/2|\n",
      "|1077|  170|\n",
      "| 683|285/6|\n",
      "| 837|  158|\n",
      "| 119| 75/6|\n",
      "|1078|   74|\n",
      "| 684|157/3|\n",
      "| 838|  155|\n",
      "| 277|  208|\n",
      "| 551|209/9|\n",
      "| 120| 14/0|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['_c0','_c1']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+\n",
      "| _c0|  _c1|Double_ID|\n",
      "+----+-----+---------+\n",
      "|null|Score|     null|\n",
      "| 412|  250|      824|\n",
      "| 680|  165|     1360|\n",
      "| 413|  157|      826|\n",
      "| 681|  167|     1362|\n",
      "| 117|  198|      234|\n",
      "|1076|305/5|     2152|\n",
      "| 682|316/9|     1364|\n",
      "| 836|325/4|     1672|\n",
      "| 118|172/2|      236|\n",
      "|1077|  170|     2154|\n",
      "| 683|285/6|     1366|\n",
      "| 837|  158|     1674|\n",
      "| 119| 75/6|      238|\n",
      "|1078|   74|     2156|\n",
      "| 684|157/3|     1368|\n",
      "| 838|  155|     1676|\n",
      "| 277|  208|      554|\n",
      "| 551|209/9|     1102|\n",
      "| 120| 14/0|      240|\n",
      "+----+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('Double_ID',df['_c0']*2).show()  #nameofnewcolumn,column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| _c0|  _c1|\n",
      "+----+-----+\n",
      "|null|Score|\n",
      "| 412|  250|\n",
      "| 680|  165|\n",
      "| 413|  157|\n",
      "| 681|  167|\n",
      "| 117|  198|\n",
      "|1076|305/5|\n",
      "| 682|316/9|\n",
      "| 836|325/4|\n",
      "| 118|172/2|\n",
      "|1077|  170|\n",
      "| 683|285/6|\n",
      "| 837|  158|\n",
      "| 119| 75/6|\n",
      "|1078|   74|\n",
      "| 684|157/3|\n",
      "| 838|  155|\n",
      "| 277|  208|\n",
      "| 551|209/9|\n",
      "| 120| 14/0|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|  ID|  _c1|\n",
      "+----+-----+\n",
      "|null|Score|\n",
      "| 412|  250|\n",
      "| 680|  165|\n",
      "| 413|  157|\n",
      "| 681|  167|\n",
      "| 117|  198|\n",
      "|1076|305/5|\n",
      "| 682|316/9|\n",
      "| 836|325/4|\n",
      "| 118|172/2|\n",
      "|1077|  170|\n",
      "| 683|285/6|\n",
      "| 837|  158|\n",
      "| 119| 75/6|\n",
      "|1078|   74|\n",
      "| 684|157/3|\n",
      "| 838|  155|\n",
      "| 277|  208|\n",
      "| 551|209/9|\n",
      "| 120| 14/0|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('_c0','ID').show()  #Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('worldcup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=spark.sql(\"Select * from worldcup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| _c0|  _c1|\n",
      "+----+-----+\n",
      "|null|Score|\n",
      "| 412|  250|\n",
      "| 680|  165|\n",
      "| 413|  157|\n",
      "| 681|  167|\n",
      "| 117|  198|\n",
      "|1076|305/5|\n",
      "| 682|316/9|\n",
      "| 836|325/4|\n",
      "| 118|172/2|\n",
      "|1077|  170|\n",
      "| 683|285/6|\n",
      "| 837|  158|\n",
      "| 119| 75/6|\n",
      "|1078|   74|\n",
      "| 684|157/3|\n",
      "| 838|  155|\n",
      "| 277|  208|\n",
      "| 551|209/9|\n",
      "| 120| 14/0|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results=spark.sql(\"Select * from worldcup where _c0>400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| _c0|  _c1|\n",
      "+----+-----+\n",
      "| 412|  250|\n",
      "| 680|  165|\n",
      "| 413|  157|\n",
      "| 681|  167|\n",
      "|1076|305/5|\n",
      "| 682|316/9|\n",
      "| 836|325/4|\n",
      "|1077|  170|\n",
      "| 683|285/6|\n",
      "| 837|  158|\n",
      "|1078|   74|\n",
      "| 684|157/3|\n",
      "| 838|  155|\n",
      "| 551|209/9|\n",
      "|1079|222/9|\n",
      "| 552|279/8|\n",
      "|1080|247/5|\n",
      "| 685|258/5|\n",
      "| 839|257/7|\n",
      "| 553|260/9|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
